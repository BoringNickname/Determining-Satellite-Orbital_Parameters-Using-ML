{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import chi2\n",
    "import pickle\n",
    "import random\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from torch.nn import functional as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domin\\AppData\\Local\\Temp/ipykernel_10944/4082650391.py:24: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_new.cpp:201.)\n",
      "  self.x = torch.tensor(x,dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.001\n",
    "epochs = 500\n",
    "batch_size = 5000\n",
    "\n",
    "#IMPORTING DATA\n",
    "#dataset variable should be a tuple of form (data, targets), each 1e5 long\n",
    "with open('./datasets/list_orbital_dataset.pickle', 'rb') as data:\n",
    "    dataset = pickle.load(data)\n",
    "\n",
    "data, targets = dataset\n",
    "\n",
    "\n",
    "#GET THE DEVICE (PREFEREABLY A GPU)\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "\n",
    "#CREATING A CUSTOM TRAINLOADER\n",
    "class DatasetClass(Dataset):\n",
    "  def __init__(self,x,y):\n",
    "    self.x = torch.tensor(x,dtype=torch.float32)\n",
    "    self.y = torch.tensor(y,dtype=torch.float32)\n",
    "    self.length = self.x.shape[0]\n",
    " \n",
    "  def __getitem__(self,idx):\n",
    "    return self.x[idx],self.y[idx]\n",
    "  def __len__(self):\n",
    "    return self.length\n",
    "\n",
    "#CUSTOM TRAIN TEST SPLIT\n",
    "def train_test_split_dataloaders(dataset, frac):\n",
    "    train = torch.utils.data.Subset(dataset, range(0, int(frac*len(dataset))))\n",
    "    test = torch.utils.data.Subset(dataset, range(int(frac*len(dataset)), len(dataset)))\n",
    "\n",
    "    trainloader = DataLoader(train, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "    testloader = DataLoader(test, batch_size=batch_size, shuffle=True, drop_last=True, pin_memory=True)\n",
    "\n",
    "    return trainloader, testloader\n",
    "\n",
    "dataset = DatasetClass(data, targets)\n",
    "trainloader, testloader = train_test_split_dataloaders(dataset,0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name:  NeuralNetwork(\n",
      "  (fc1): Linear(in_features=50, out_features=10, bias=True)\n",
      "  (fc2): Linear(in_features=10, out_features=6, bias=True)\n",
      ")\n",
      "device being used:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "#DEFINE A NEURAL NETWORK\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(50,10)\n",
    "        self.fc2 = nn.Linear(10,6)\n",
    "        # self.fc3 = nn.Linear(10,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.view(batch_size, -1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        # x = F.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "#A DIFFERENT ITERATION OF THE NETWORK\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        # print('input shape', input_shape)\n",
    "        self.cl1 = nn.Conv1d(1,3,3,1)\n",
    "\n",
    "        self.cl2 = nn.Conv1d(3,5,3,1)\n",
    "        self.fc1 = nn.Linear(,6)\n",
    "    def forward(self,x):\n",
    "        x = x.view(batch_size, 1)\n",
    "        print('batch input into the model', x.size())\n",
    "        x = torch.relu(self.cl1(x))\n",
    "        x = torch.max_pool1d(x,3)\n",
    "        x = torch.relu(self.cl2(x))\n",
    "        print('after first conv1d', x.size())\n",
    "        x = torch.max_pool1d(x,3)\n",
    "        print('after second conv1d', x.size())\n",
    "        x = x.view(batch_size, -1)\n",
    "        print('size after flattening the conv layers', x.size())\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "#INSTANTIATE THE MODEL\n",
    "model = NeuralNetwork()\n",
    "print('model name: ', model)\n",
    "device = get_device()\n",
    "print('device being used: ', device)\n",
    "model.to(device)\n",
    "\n",
    "#OPTIMIZER AND LOSS FUNCTION\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
    "loss_fn = nn.MSELoss()\n",
    "accuracy, train_losses, test_losses = [],[],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "softmax() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim, torch.dtype dtype)\n * (Tensor input, name dim, *, torch.dtype dtype)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24852/3934069426.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;31m#calculate loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\satellite\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24852/1789704245.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;31m# x = F.sigmoid(self.fc3(x))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: softmax() received an invalid combination of arguments - got (Tensor), but expected one of:\n * (Tensor input, int dim, torch.dtype dtype)\n * (Tensor input, name dim, *, torch.dtype dtype)\n"
     ]
    }
   ],
   "source": [
    "#TRAINING LOOP\n",
    "for i in range(epochs):\n",
    "    for j, (x_train, y_train) in enumerate(trainloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_train.to(device))\n",
    "\n",
    "        #calculate loss\n",
    "        loss = loss_fn(output, y_train.to(device))\n",
    "\n",
    "        #backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if i%50==0:\n",
    "        train_losses.append(loss)\n",
    "        # accuracy.append(acc)\n",
    "        print(f'epoch:{i}, loss:{loss}')        \n",
    "\n",
    "print('Finished!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1750, 1.0000, 0.9236, 1.0000, 0.2444, 1.0000],\n",
      "        [0.1750, 1.0000, 0.9236, 1.0000, 0.2444, 1.0000],\n",
      "        [0.1750, 1.0000, 0.9236, 1.0000, 0.2444, 1.0000],\n",
      "        ...,\n",
      "        [0.1750, 1.0000, 0.9236, 1.0000, 0.2444, 1.0000],\n",
      "        [0.1750, 1.0000, 0.9236, 1.0000, 0.2444, 1.0000],\n",
      "        [0.1750, 1.0000, 0.9236, 1.0000, 0.2444, 1.0000]], device='cuda:0',\n",
      "       grad_fn=<SigmoidBackward0>) tensor([[0.3297, 0.7984, 0.9758, 0.6918, 0.3111, 4.9062],\n",
      "        [0.0341, 0.4528, 1.1298, 0.0983, 0.1989, 4.3417],\n",
      "        [0.1179, 3.0242, 1.4361, 1.2545, 0.3100, 4.1648],\n",
      "        ...,\n",
      "        [0.0553, 3.1321, 0.2169, 5.8220, 0.2745, 1.5065],\n",
      "        [0.3205, 0.2641, 0.8986, 4.2232, 0.2045, 3.3947],\n",
      "        [0.1678, 5.2859, 1.0647, 5.7189, 0.2894, 3.1746]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for j, (x_test, y_test) in enumerate(testloader):\n",
    "    output = model(x_test.to(device))\n",
    "\n",
    "    print(output, y_test)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b9de385d9172775ed93a54b56cf86bfd3a93063b69824e633a3be73300bcff6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
